#!/usr/bin/env python3
"""
æµ‹è¯•æ¶ˆæ¯é˜Ÿåˆ—ä¿®å¤
éªŒè¯ä»»åŠ¡é˜Ÿåˆ—å’Œç»“æœé˜Ÿåˆ—æ˜¯å¦æ­£ç¡®åˆ†ç¦»
"""

import asyncio
import json
import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from backend.models.token import TokenData, AnalysisResult
from backend.services.message_queue import MessageQueue

async def test_message_queue_separation():
    """æµ‹è¯•æ¶ˆæ¯é˜Ÿåˆ—çš„ä»»åŠ¡å’Œç»“æœåˆ†ç¦»"""
    print("ğŸ§ª æµ‹è¯•æ¶ˆæ¯é˜Ÿåˆ—ä¿®å¤...")
    
    # åˆå§‹åŒ–æ¶ˆæ¯é˜Ÿåˆ—
    message_queue = MessageQueue()
    await message_queue.initialize()
    
    # åˆ›å»ºæµ‹è¯•ä»£å¸æ•°æ®
    token_data = TokenData(
        name="Test Token",
        symbol="TEST",
        uri="https://example.com",
        mint="DztwRrFQF4tbJLxQo9EQ7fk36xQkvoiYwxBLBQW3pump",
        bonding_curve="bonding_curve_address",
        user="user_address",
        creator="creator_address",
        timestamp=1642723200,
        virtual_token_reserves=1000000,
        virtual_sol_reserves=500,
        real_token_reserves=800000,
        token_total_supply=1000000000,
        created_at=datetime.now()
    )
    
    # åˆ›å»ºæµ‹è¯•åˆ†æç»“æœ
    analysis_result = AnalysisResult(
        token_mint="DztwRrFQF4tbJLxQo9EQ7fk36xQkvoiYwxBLBQW3pump",
        token_symbol="TEST",
        token_name="Test Token",
        status="COMPLETED",
        progress=100.0,
        narrative_analysis="Test narrative",
        risk_assessment="Test risk",
        market_analysis="Test market",
        ai_summary="Test summary",
        investment_recommendation="Test recommendation",
        analysis_started_at=datetime.now(),
        analysis_completed_at=datetime.now()
    )
    
    print("âœ… æµ‹è¯•æ•°æ®åˆ›å»ºæˆåŠŸ")
    
    # æµ‹è¯•1: æ·»åŠ åˆ†æä»»åŠ¡
    print("\nğŸ” æµ‹è¯•1: æ·»åŠ åˆ†æä»»åŠ¡åˆ°ä»»åŠ¡é˜Ÿåˆ—")
    await message_queue.add_analysis_task(token_data)
    print("âœ… ä»»åŠ¡æ·»åŠ æˆåŠŸ")
    
    # æµ‹è¯•2: ä»ä»»åŠ¡é˜Ÿåˆ—è·å–ä»»åŠ¡
    print("\nğŸ” æµ‹è¯•2: ä»ä»»åŠ¡é˜Ÿåˆ—è·å–ä»»åŠ¡")
    task = await message_queue.get_analysis_task()
    if task and "token_data" in task:
        print(f"âœ… ä»»åŠ¡è·å–æˆåŠŸ: {task['task_id']}")
        print(f"   åŒ…å«token_data: {task['token_data']['symbol']}")
    else:
        print(f"âŒ ä»»åŠ¡è·å–å¤±è´¥æˆ–æ ¼å¼é”™è¯¯: {task}")
        return False
    
    # æµ‹è¯•3: å‘å¸ƒåˆ†æç»“æœ
    print("\nğŸ” æµ‹è¯•3: å‘å¸ƒåˆ†æç»“æœåˆ°ç»“æœé˜Ÿåˆ—")
    await message_queue.publish_analysis_result(analysis_result)
    print("âœ… ç»“æœå‘å¸ƒæˆåŠŸ")
    
    # æµ‹è¯•4: ä»ç»“æœé˜Ÿåˆ—è·å–ç»“æœ
    print("\nğŸ” æµ‹è¯•4: ä»ç»“æœé˜Ÿåˆ—è·å–ç»“æœ")
    result_message = await message_queue.get_result_message()
    if result_message:
        try:
            result_data = json.loads(result_message)
            if result_data.get("type") == "analysis_complete":
                print(f"âœ… ç»“æœè·å–æˆåŠŸ: {result_data['type']}")
                print(f"   ä»£å¸ç¬¦å·: {result_data['data']['token_symbol']}")
            else:
                print(f"âŒ ç»“æœæ ¼å¼é”™è¯¯: {result_data}")
                return False
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            return False
    else:
        print("âŒ ç»“æœè·å–å¤±è´¥")
        return False
    
    # æµ‹è¯•5: éªŒè¯é˜Ÿåˆ—åˆ†ç¦»
    print("\nğŸ” æµ‹è¯•5: éªŒè¯é˜Ÿåˆ—åˆ†ç¦»")
    
    # æ·»åŠ æ›´å¤šä»»åŠ¡å’Œç»“æœ
    await message_queue.add_analysis_task(token_data)
    await message_queue.publish_analysis_result(analysis_result)
    
    # æ£€æŸ¥ä»»åŠ¡é˜Ÿåˆ—
    task_queue_size = await message_queue.get_queue_size()
    print(f"   ä»»åŠ¡é˜Ÿåˆ—å¤§å°: {task_queue_size}")
    
    # è·å–ä»»åŠ¡åº”è¯¥å¾—åˆ°ä»»åŠ¡æ ¼å¼
    task2 = await message_queue.get_analysis_task()
    if task2 and "token_data" in task2:
        print("âœ… ä»»åŠ¡é˜Ÿåˆ—æ­£ç¡®è¿”å›ä»»åŠ¡æ ¼å¼")
    else:
        print("âŒ ä»»åŠ¡é˜Ÿåˆ—è¿”å›æ ¼å¼é”™è¯¯")
        return False
    
    # è·å–ç»“æœåº”è¯¥å¾—åˆ°ç»“æœæ ¼å¼
    result2 = await message_queue.get_result_message()
    if result2:
        try:
            result_data2 = json.loads(result2)
            if result_data2.get("type") == "analysis_complete":
                print("âœ… ç»“æœé˜Ÿåˆ—æ­£ç¡®è¿”å›ç»“æœæ ¼å¼")
            else:
                print("âŒ ç»“æœé˜Ÿåˆ—è¿”å›æ ¼å¼é”™è¯¯")
                return False
        except:
            print("âŒ ç»“æœé˜Ÿåˆ—è¿”å›æ— æ•ˆJSON")
            return False
    else:
        print("âŒ ç»“æœé˜Ÿåˆ—æ— æ•°æ®")
        return False
    
    print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¶ˆæ¯é˜Ÿåˆ—ä¿®å¤æˆåŠŸ")
    return True

async def test_ai_analyzer_compatibility():
    """æµ‹è¯•AIåˆ†æå™¨å…¼å®¹æ€§"""
    print("\nğŸ§ª æµ‹è¯•AIåˆ†æå™¨å…¼å®¹æ€§...")
    
    # æ¨¡æ‹ŸAIåˆ†æå™¨å¤„ç†ä»»åŠ¡çš„åœºæ™¯
    message_queue = MessageQueue()
    await message_queue.initialize()
    
    # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
    token_data = TokenData(
        name="Test Token",
        symbol="TEST",
        uri="https://example.com",
        mint="DztwRrFQF4tbJLxQo9EQ7fk36xQkvoiYwxBLBQW3pump",
        bonding_curve="bonding_curve_address",
        user="user_address",
        creator="creator_address",
        timestamp=1642723200,
        virtual_token_reserves=1000000,
        virtual_sol_reserves=500,
        real_token_reserves=800000,
        token_total_supply=1000000000,
        created_at=datetime.now()
    )
    
    # æ·»åŠ ä»»åŠ¡
    await message_queue.add_analysis_task(token_data)
    
    # æ¨¡æ‹ŸAIåˆ†æå™¨è·å–ä»»åŠ¡
    task = await message_queue.get_analysis_task()
    
    try:
        # è¿™æ˜¯AIåˆ†æå™¨ä¸­ä¼šæ‰§è¡Œçš„ä»£ç 
        token_data_dict = task["token_data"]
        reconstructed_token = TokenData(**token_data_dict)
        
        print(f"âœ… AIåˆ†æå™¨å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        print(f"   é‡æ„çš„ä»£å¸: {reconstructed_token.symbol}")
        return True
        
    except KeyError as e:
        print(f"âŒ AIåˆ†æå™¨å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: ç¼ºå°‘é”® {e}")
        return False
    except Exception as e:
        print(f"âŒ AIåˆ†æå™¨å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

async def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸš€ å¼€å§‹æ¶ˆæ¯é˜Ÿåˆ—ä¿®å¤éªŒè¯æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        test_message_queue_separation,
        test_ai_analyzer_compatibility
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if await test():
                passed += 1
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¶ˆæ¯é˜Ÿåˆ—ä¿®å¤æˆåŠŸ")
        return 0
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
        return 1

if __name__ == "__main__":
    exit(asyncio.run(main()))
