"""
ä½¿ç”¨ç¤ºä¾‹ - å±•ç¤ºå¦‚ä½•ä½¿ç”¨åŸºäºæ­£ç¡®Googleå¼•æ“çš„çˆ¬è™«
"""
import os
import time
from google_search_crawler import GoogleSearchCrawler, MarketAnalysisCrawler

def example_basic_crawling():
    """åŸºç¡€çˆ¬å–ç¤ºä¾‹"""
    print("=== åŸºç¡€çˆ¬å–ç¤ºä¾‹ ===")
    
    crawler = GoogleSearchCrawler()
    
    # å•ä¸ªæŸ¥è¯¢çˆ¬å–
    queries = [
        "äººå·¥æ™ºèƒ½åˆ›ä¸šæœºä¼š",
        "åŒºå—é“¾æŠ€æœ¯åº”ç”¨",
        "æ–°èƒ½æºæ±½è½¦å¸‚åœºåˆ†æ"
    ]
    
    for query in queries:
        print(f"\næ­£åœ¨çˆ¬å–: {query}")
        result = crawler.crawl_and_store(
            query=query,
            num_results=20,
            query_intent='research'
        )
        
        if result['success']:
            print(f"âœ“ æˆåŠŸçˆ¬å– {result['results_count']} æ¡ç»“æœ")
            stats = result['stats']
            print(f"  - å”¯ä¸€åŸŸå: {stats.get('unique_domains', 0)}")
            print(f"  - ä¸»è¦ä¿¡æ¯æº: {list(stats.get('domain_distribution', {}).keys())[:3]}")
        else:
            print(f"âœ— çˆ¬å–å¤±è´¥: {result['message']}")
        
        # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        time.sleep(3)

def example_batch_crawling():
    """æ‰¹é‡çˆ¬å–ç¤ºä¾‹"""
    print("\n=== æ‰¹é‡çˆ¬å–ç¤ºä¾‹ ===")
    
    # åˆ›å»ºæ‰¹é‡æŸ¥è¯¢æ–‡ä»¶
    batch_queries = [
        "Pythonç¼–ç¨‹æ•™ç¨‹",
        "æœºå™¨å­¦ä¹ ç®—æ³•",
        "æ•°æ®ç§‘å­¦å·¥å…·",
        "æ·±åº¦å­¦ä¹ æ¡†æ¶",
        "äººå·¥æ™ºèƒ½åº”ç”¨"
    ]
    
    batch_file = "batch_queries.txt"
    with open(batch_file, 'w', encoding='utf-8') as f:
        for query in batch_queries:
            f.write(f"{query}\n")
    
    crawler = GoogleSearchCrawler()
    
    print(f"æ‰¹é‡çˆ¬å– {len(batch_queries)} ä¸ªæŸ¥è¯¢...")
    result = crawler.batch_crawl(
        queries=batch_queries,
        num_results_per_query=15
    )
    
    print(f"æ‰¹é‡çˆ¬å–å®Œæˆ:")
    print(f"  æˆåŠŸ: {result['successful_queries']}/{len(batch_queries)}")
    print(f"  æ€»ç»“æœ: {result['total_results']} æ¡")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if os.path.exists(batch_file):
        os.remove(batch_file)

def example_search_and_export():
    """æœç´¢å’Œå¯¼å‡ºç¤ºä¾‹"""
    print("\n=== æœç´¢å’Œå¯¼å‡ºç¤ºä¾‹ ===")
    
    crawler = GoogleSearchCrawler()
    
    # æœç´¢å·²å­˜å‚¨çš„æ•°æ®
    print("æœç´¢å·²å­˜å‚¨çš„æ•°æ®...")
    results = crawler.search_stored_results(
        query="äººå·¥æ™ºèƒ½",
        min_quality_score=0.5,
        size=10
    )
    
    if results:
        print(f"æ‰¾åˆ° {len(results)} æ¡é«˜è´¨é‡ç»“æœ:")
        for i, result in enumerate(results[:3], 1):
            print(f"{i}. {result.get('title', 'N/A')}")
            print(f"   è´¨é‡åˆ†æ•°: {result.get('quality_score', 0):.2f}")
            print(f"   åˆ†ç±»: {result.get('category', 'N/A')}")
    
    # å¯¼å‡ºè®­ç»ƒæ•°æ®
    print("\nå¯¼å‡ºå¤§æ¨¡å‹è®­ç»ƒæ•°æ®...")
    
    # å¯¼å‡ºJSONLæ ¼å¼
    jsonl_data = crawler.export_training_data(
        output_format='jsonl',
        min_quality_score=0.6,
        output_file='training_data.jsonl'
    )
    
    if jsonl_data:
        lines = jsonl_data.count('\n') + 1
        print(f"âœ“ JSONLæ ¼å¼å¯¼å‡ºå®Œæˆ: {lines} æ¡è®°å½•")
    
    # å¯¼å‡ºæŒ‡ä»¤-å“åº”å¯¹æ ¼å¼
    instruction_data = crawler.export_training_data(
        output_format='instruction_pairs',
        min_quality_score=0.6,
        output_file='instruction_pairs.jsonl'
    )
    
    if instruction_data:
        lines = instruction_data.count('\n') + 1
        print(f"âœ“ æŒ‡ä»¤å¯¹æ ¼å¼å¯¼å‡ºå®Œæˆ: {lines} æ¡è®°å½•")

def example_market_analysis():
    """å¸‚åœºåˆ†æç¤ºä¾‹"""
    print("\n=== å¸‚åœºåˆ†æç¤ºä¾‹ ===")
    
    market_crawler = MarketAnalysisCrawler()
    
    # åˆ†æç‰¹å®šå¸‚åœºé¢†åŸŸ
    sector = "äººå·¥æ™ºèƒ½"
    print(f"åˆ†æå¸‚åœºé¢†åŸŸ: {sector}")
    
    result = market_crawler.analyze_market_sector(
        sector=sector,
        num_results=50
    )
    
    print(f"å¸‚åœºåˆ†æå®Œæˆ:")
    print(f"  æˆåŠŸæŸ¥è¯¢: {result['successful_queries']}")
    print(f"  æ”¶é›†æ•°æ®: {result['total_results']} æ¡")
    
    # ç”Ÿæˆå¸‚åœºæŠ¥å‘Š
    report_file = f"{sector}_market_report.md"
    report = market_crawler.generate_market_report(
        sector=sector,
        output_file=report_file
    )
    
    print(f"  æŠ¥å‘Šæ–‡ä»¶: {report_file}")
    
    # ç›‘æ§åˆ›ä¸šè¶‹åŠ¿
    print(f"\nç›‘æ§åˆ›ä¸šè¶‹åŠ¿...")
    industries = ["äººå·¥æ™ºèƒ½", "åŒºå—é“¾", "æ–°èƒ½æº"]
    
    trend_result = market_crawler.monitor_startup_trends(
        industries=industries,
        num_results=30
    )
    
    print(f"è¶‹åŠ¿ç›‘æ§å®Œæˆ:")
    print(f"  æ¶‰åŠè¡Œä¸š: {len(industries)}")
    print(f"  æ”¶é›†æ•°æ®: {trend_result['total_results']} æ¡")

def example_advanced_features():
    """é«˜çº§åŠŸèƒ½ç¤ºä¾‹"""
    print("\n=== é«˜çº§åŠŸèƒ½ç¤ºä¾‹ ===")
    
    crawler = GoogleSearchCrawler()
    
    # è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯
    print("ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯:")
    stats = crawler.get_stats()
    
    if stats:
        print(f"  æ€»æ–‡æ¡£æ•°: {stats.get('total_documents', 0):,}")
        print(f"  ç´¢å¼•å¤§å°: {stats.get('index_size', 0):,} bytes")
        
        # åˆ†ç±»åˆ†å¸ƒ
        categories = stats.get('categories', {})
        if categories:
            print(f"  å†…å®¹åˆ†ç±»:")
            for category, count in list(categories.items())[:5]:
                print(f"    {category}: {count} æ¡")
        
        # è¯­è¨€åˆ†å¸ƒ
        languages = stats.get('languages', {})
        if languages:
            print(f"  è¯­è¨€åˆ†å¸ƒ:")
            for lang, count in languages.items():
                lang_name = {'zh': 'ä¸­æ–‡', 'en': 'è‹±æ–‡', 'mixed': 'æ··åˆ'}.get(lang, lang)
                print(f"    {lang_name}: {count} æ¡")
    
    # è·å–è®­ç»ƒæ•°æ®æ ·æœ¬
    print(f"\nè®­ç»ƒæ•°æ®æ ·æœ¬:")
    samples = crawler.get_training_data_sample(size=3)
    
    for i, sample in enumerate(samples, 1):
        print(f"\næ ·æœ¬ {i}:")
        print(f"  æŸ¥è¯¢: {sample.get('query', 'N/A')}")
        print(f"  æ ‡é¢˜: {sample.get('title', 'N/A')[:50]}...")
        print(f"  è´¨é‡åˆ†æ•°: {sample.get('quality_score', 0):.2f}")
        print(f"  è®­ç»ƒæ–‡æœ¬é¢„è§ˆ:")
        training_text = sample.get('llm_training_text', '')
        print(f"    {training_text[:100]}...")

def example_custom_search_parameters():
    """è‡ªå®šä¹‰æœç´¢å‚æ•°ç¤ºä¾‹"""
    print("\n=== è‡ªå®šä¹‰æœç´¢å‚æ•°ç¤ºä¾‹ ===")
    
    crawler = GoogleSearchCrawler()
    
    # ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°
    result = crawler.crawl_and_store(
        query="machine learning tutorial",
        num_results=30,
        query_intent='educational',
        lang='en',
        region='us',
        safe='active',
        sleep_interval=1.5,
        timeout=15
    )
    
    if result['success']:
        print(f"âœ“ è‡ªå®šä¹‰å‚æ•°çˆ¬å–æˆåŠŸ")
        print(f"  ç»“æœæ•°: {result['results_count']}")
        print(f"  æŸ¥è¯¢æ„å›¾: educational")
        print(f"  è¯­è¨€: è‹±æ–‡")
        print(f"  åŒºåŸŸ: ç¾å›½")
    
    # æŒ‰åˆ†ç±»æœç´¢
    print(f"\næŒ‰åˆ†ç±»æœç´¢æ•™ç¨‹å†…å®¹:")
    tutorial_results = crawler.search_stored_results(
        category='tutorial',
        min_quality_score=0.7,
        size=5
    )
    
    for i, result in enumerate(tutorial_results, 1):
        print(f"{i}. {result.get('title', 'N/A')}")
        print(f"   åˆ†ç±»: {result.get('category', 'N/A')}")
        print(f"   è´¨é‡: {result.get('quality_score', 0):.2f}")

def main():
    """è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("Googleæœç´¢çˆ¬è™«ä½¿ç”¨ç¤ºä¾‹")
    print("åŸºäºæ­£ç¡®çš„Googleæœç´¢å¼•æ“")
    print("=" * 50)
    
    try:
        # åŸºç¡€åŠŸèƒ½ç¤ºä¾‹
        example_basic_crawling()
        
        # æ‰¹é‡çˆ¬å–ç¤ºä¾‹
        example_batch_crawling()
        
        # æœç´¢å’Œå¯¼å‡ºç¤ºä¾‹
        example_search_and_export()
        
        # å¸‚åœºåˆ†æç¤ºä¾‹
        example_market_analysis()
        
        # é«˜çº§åŠŸèƒ½ç¤ºä¾‹
        example_advanced_features()
        
        # è‡ªå®šä¹‰å‚æ•°ç¤ºä¾‹
        example_custom_search_parameters()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆ!")
        print("\nğŸ’¡ æç¤º:")
        print("- æ‰€æœ‰æ•°æ®å·²å­˜å‚¨åœ¨Elasticsearchä¸­")
        print("- å¯ä»¥ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·è¿›è¡Œæ›´å¤šæ“ä½œ")
        print("- å¯¼å‡ºçš„è®­ç»ƒæ•°æ®å¯ç›´æ¥ç”¨äºå¤§æ¨¡å‹è®­ç»ƒ")
        print("- æ”¯æŒå¤šç§æŸ¥è¯¢æ„å›¾å’Œå†…å®¹åˆ†ç±»")
        
    except KeyboardInterrupt:
        print("\nç¤ºä¾‹è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"ç¤ºä¾‹æ‰§è¡Œå‡ºé”™: {e}")

if __name__ == "__main__":
    main()
